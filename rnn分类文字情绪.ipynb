{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-14T06:18:01.179858400Z",
     "start_time": "2024-01-14T06:18:00.419747800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   x  y\n0  101,5342,2047,3595,8496,2013,1996,18643,3197,1...  0\n1  101,3397,2053,15966,1010,2069,4450,2098,18201,...  0\n2  101,2008,7459,2049,3494,1998,10639,2015,2242,2...  1\n3  101,3464,12580,8510,2000,3961,1996,2168,2802,1...  0\n4  101,2006,1996,5409,7195,1011,1997,1011,1996,10...  0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>101,5342,2047,3595,8496,2013,1996,18643,3197,1...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>101,3397,2053,15966,1010,2069,4450,2098,18201,...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>101,2008,7459,2049,3494,1998,10639,2015,2242,2...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>101,3464,12580,8510,2000,3961,1996,2168,2802,1...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>101,2006,1996,5409,7195,1011,1997,1011,1996,10...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data():\n",
    "    import pandas as pd\n",
    "    data = pd.read_csv('data/sst2/data.csv')\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = load_data()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "(65000,\n (tensor([  101,  5342,  2047,  3595,  8496,  2013,  1996, 18643,  3197,   102,\n              0,     0,     0,     0,     0]),\n  0))"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.data.iloc[index]\n",
    "        \n",
    "        x = [int(i) for i in x.split(\",\")]\n",
    "        x = torch.LongTensor(x)\n",
    "        \n",
    "        y = int(y)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "dataset = Dataset(data)\n",
    "len(dataset), dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T06:25:10.533681700Z",
     "start_time": "2024-01-14T06:25:08.115082900Z"
    }
   },
   "id": "2ee888427b830393"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(2032,\n [tensor([[  101,  1037,  2132,  1011,  6769,  1011,  1011, 19897,  2517,   102,\n               0,     0,     0,     0,     0],\n          [  101, 21864, 15952,  7726,  3689,  3595, 10428,   102,     0,     0,\n               0,     0,     0,     0,     0],\n          [  101,  1005,  1055,  2525,  1037,  8257,  1999,  1996,  2142,  2163,\n            1012,   102,     0,     0,     0],\n          [  101,  2000,  2031,  6404,  2673,  2002,  2412,  2354,  2055, 11717,\n           23873,   102,     0,     0,     0],\n          [  101,  2009, 18276,  2003,  2008,  2009,  1005,  1055,  2036,  2028,\n            1997,  1996,  6047,  4355,   102],\n          [  101,  1037,  2092,  1011, 10849,  5891,  2004,  2028,   102,     0,\n               0,     0,     0,     0,     0],\n          [  101,  2008, 13695,  2630, 10188,  2046,  2028,  1997,  1996,  2621,\n            1005,  1055,  2087, 22512,   102],\n          [  101,  1037,  2034,  1011,  2465,  1010, 12246,  5994,  1038,  3185,\n            2008,  6464, 13585,  2048,   102],\n          [  101,  2024,  2061,  5220,  2017,  2453,  2004,  2092,  2022,  3666,\n            1037,  2128, 15532,   102,     0],\n          [  101,  2003,  2210,  2062,  2084,  1037,  6670,  3185,  2881,  2000,\n            3102,  2051,   102,     0,     0],\n          [  101,  8491, 15063, 11680,  1010,  2062, 27118,  2094, 16874,  4765,\n            3924,  1998, 14726,  2135,   102],\n          [  101,  2097,  2022,  2006,  2678,  2146,  2077,  2027,  4982,  2039,\n            1998,  2017,  2064,  3524,   102],\n          [  101, 27885,  3630, 25171,  4038,   102,     0,     0,     0,     0,\n               0,     0,     0,     0,     0],\n          [  101,  9530, 18532, 24759,  8082,   102,     0,     0,     0,     0,\n               0,     0,     0,     0,     0],\n          [  101,  6057,  1010, 22557, 29118,   102,     0,     0,     0,     0,\n               0,     0,     0,     0,     0],\n          [  101,  1010,  1996,  7982,  4165,  2066,  9202,  4623,  1012,   102,\n               0,     0,     0,     0,     0],\n          [  101,  5223,  2000,  7697,  2115,  2159,  2185,  2013,  1996,  4871,\n             102,     0,     0,     0,     0],\n          [  101,  7641,  1005,  1055, 10473,  2143,  2144,  1996,  3428, 11338,\n           12274, 12179,   102,     0,     0],\n          [  101,  2096,  5121,  2062, 19176,  2594,  2084,  2049,  2827, 13637,\n            1010, 23204,  2072,  1005,   102],\n          [  101,  2066,  2087,  5691,  2055,  1996,  6770, 28067,  1997,  2919,\n            5248,   102,     0,     0,     0],\n          [  101, 17398,  2732, 15107,  1005,  1055,  2567,  2175, 17460,  2007,\n            1996, 28806,  5474,  3898,   102],\n          [  101,  7502, 18847,  2669,  3560,   102,     0,     0,     0,     0,\n               0,     0,     0,     0,     0],\n          [  101,  2042,  3625,  2005,  5128,  2362,  2151,  5691,  1997,  3327,\n            3643,  2030,  7857,   102,     0],\n          [  101,  2256,  3226,  2003,  3753,  2091,  1996, 11848,  2007,  1996,\n           10768, 21735,  1997,  1037,   102],\n          [  101,  5021,  3347,  5910,   102,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0],\n          [  101,  2097,  3233,  1999,  2925,  2086,  2004,  2019,  3449,  2080,\n           15417,  3986,  2000,  1996,   102],\n          [  101,  2008,  2045,  1005,  1055,  2053,  2060,  3114,  2339,  3087,\n            2323,  8572, 10397,  2009,   102],\n          [  101,  2021,  2053,  1011, 14652,  2529,  9552,  2027,  2024,  1998,\n             102,     0,     0,     0,     0],\n          [  101,  2055,  2028,  1999,  2093, 18201,  2015,  1999,  2317,  1005,\n            1055, 23852,  2135,  7968,   102],\n          [  101,  2037,  2173,  1999,  1996,  2088,   102,     0,     0,     0,\n               0,     0,     0,     0,     0],\n          [  101,  2442,  2022,  1996,  2203,  1997,  1996,  2088,   102,     0,\n               0,     0,     0,     0,     0],\n          [  101,  1996,  3865,   102,     0,     0,     0,     0,     0,     0,\n               0,     0,     0,     0,     0]]),\n  tensor([1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n          1, 1, 0, 1, 0, 1, 0, 0])])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "len(loader), next(iter(loader))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T06:37:00.190987100Z",
     "start_time": "2024-01-14T06:37:00.118428900Z"
    }
   },
   "id": "9e6efe60793220f4"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([8, 2])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(30522, 128)\n",
    "        self.rnn = torch.nn.LSTM(128, 128, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(128, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.rnn(x)\n",
    "        x = x[:, -1]\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = Model()\n",
    "model(torch.ones(8, 15).long()).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T07:26:32.822499200Z",
     "start_time": "2024-01-14T07:26:32.750035300Z"
    }
   },
   "id": "e0437ec31a58f694"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Loss: 0.69573974609375\n",
      "Epoch: 0, Batch: 100, Loss: 0.6915282607078552\n",
      "Epoch: 0, Batch: 200, Loss: 0.6666579246520996\n",
      "Epoch: 0, Batch: 300, Loss: 0.6574747562408447\n",
      "Epoch: 0, Batch: 400, Loss: 0.5668902397155762\n",
      "Epoch: 0, Batch: 500, Loss: 0.5231608152389526\n",
      "Epoch: 0, Batch: 600, Loss: 0.49259087443351746\n",
      "Epoch: 0, Batch: 700, Loss: 0.4962180256843567\n",
      "Epoch: 0, Batch: 800, Loss: 0.46396827697753906\n",
      "Epoch: 0, Batch: 900, Loss: 0.4237833321094513\n",
      "Epoch: 0, Batch: 1000, Loss: 0.34554892778396606\n",
      "Epoch: 0, Batch: 1100, Loss: 0.5370961427688599\n",
      "Epoch: 0, Batch: 1200, Loss: 0.49347299337387085\n",
      "Epoch: 0, Batch: 1300, Loss: 0.5599779486656189\n",
      "Epoch: 0, Batch: 1400, Loss: 0.347579687833786\n",
      "Epoch: 0, Batch: 1500, Loss: 0.1854720562696457\n",
      "Epoch: 0, Batch: 1600, Loss: 0.46506625413894653\n",
      "Epoch: 0, Batch: 1700, Loss: 0.4102201759815216\n",
      "Epoch: 0, Batch: 1800, Loss: 0.30582094192504883\n",
      "Epoch: 0, Batch: 1900, Loss: 0.30795541405677795\n",
      "Epoch: 0, Batch: 2000, Loss: 0.3772348165512085\n"
     ]
    }
   ],
   "source": [
    "class train():\n",
    "    def __init__(self, model, loader):\n",
    "        self.model = model\n",
    "        self.loader = loader\n",
    "        \n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        \n",
    "    def __call__(self, epoch):\n",
    "        self.model.train()\n",
    "        \n",
    "        for batch, (x, y) in enumerate(self.loader):\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            y_hat = self.model(x)\n",
    "            loss = self.criterion(y_hat, y)\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            if batch % 100 == 0:\n",
    "                print(f\"Epoch: {epoch}, Batch: {batch}, Loss: {loss.item()}\")\n",
    "                \n",
    "        torch.save(model, 'model/7.model')\n",
    "\n",
    "train(model, loader)(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T07:28:31.150039500Z",
     "start_time": "2024-01-14T07:27:53.761601600Z"
    }
   },
   "id": "6c3155a33d86228b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def test():\n",
    "    model = torch.load('model/7.model')\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(100):\n",
    "        x, y = next(iter(loader))\n",
    "\n",
    "        out = model(x).argmax(dim=1)\n",
    "\n",
    "        correct += (out == y).sum().item()\n",
    "        total += len(y)\n",
    "\n",
    "    print(correct / total)\n",
    "\n",
    "\n",
    "test()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T07:28:45.415146300Z",
     "start_time": "2024-01-14T07:28:44.633483700Z"
    }
   },
   "id": "bc601fac5c48d85f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2503301c681a5d2f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
